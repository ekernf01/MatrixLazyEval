---
title: "LazyMatrix Demo"
author: "Eric Kernfeld"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LazyMatrix_Demo}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

### An introduction to the `LazyMatrix` package

Sometimes it doesn't make sense to store your matrices explicitly. `LazyMatrix` allows you to store them in clever ways that *save memory* and allow for *fast matrix-vector multiplication*.  In turn, this facilitates speedups for algorithms that only require matrix-vector products -- for example, the very popular iteratively restarted lanczos bidiagonalization often used for PCA. 

In the following examples, you start with a large, sparse matrix $M$, and you want to perform simple operations without causing it to become dense. This vignette will compare the performance of `LazyMatrix` against a naive approach using only the `Matrix` package. For the demo data, you'll need the R package `MAST`.

```{r}
library(Matrix)
data(CAex)
#M = CAex
M = t(MAST::maits$expressionmat) 
M = M * matrix(rbinom(prod(dim(M)), p = 0.01, 1), nrow(M), ncol(M))
M = Matrix::Matrix(M, sparse = T )
M = cbind(M, M, M, M, M, M, M, M, M, M)
dim(M)
class(M)
sum( M > 0 )
sum( M > 0 ) / prod( dim(M) )
library(MatrixLazyEval)
```

##### Example

You wish to shift the rows of $M$ to have mean 0. One way to accomplish this is to subtract a matrix $RE$ where $R\in \mathbb{R^{m\times 1}}$ contains the row-means in a column and $E\in \mathbb{R^{1\times n}}$ contains just 1's. Using the `LEFT` and `RIGHT` keywords inside the evaluation rule, you can enforce that evaluation is done efficiently, without explicitly forming the dense and painfully redundant matrix $RE$. In other words, always do $xMy + (xR)(Ey)$ rather than $x(M + RE)y$.

```{r}
R    = matrix( nrow = nrow(M), ncol = 1, data = rowMeans( M ) )
ONES = matrix( ncol = ncol(M), nrow = 1, data = 1 )
M_shifted = M - R %*% ONES
M_shifted_lazy = NewLazyMatrix( components = list("M" = M, "R" = R, "ONES" = ONES ), 
                                dim = dim(M),
                                eval_rule  = "(LEFT %*% M %*% RIGHT) - (LEFT %*% R) %*% (ONES %*% RIGHT)" )
object.size(M_shifted)
object.size(M_shifted_lazy)
x = rnorm( ncol( M ) )
microbenchmark::microbenchmark({M_shifted      %*% x})
microbenchmark::microbenchmark({M_shifted_lazy %*% x})
```

##### Example

You wish to replace $M$ with residuals from a regression with a few covariates $X$, which means you need $Z \equiv M - X(X^TX)^{-1}X^TM$. With relatively few columns in $X$, it's much faster to do $wMy - (wX(X^TX)^{-1})(X^TMy)$ than $M - X(X^TX)^{-1}X^TM$.

```{r}

X = as.matrix( data.frame( intercept = 1, slope = 1:nrow(M) ) )
XtXinv = solve(t(X) %*% X) # this is just 2 by 2
M_regressed = M - X %*% XtXinv %*% t(X) %*% M
M_regressed_lazy = NewLazyMatrix( components = list("M" = M, "X" = X, "XtXinv" = XtXinv ), 
                                  dim = dim(M),
                                  eval_rule  = "( LEFT %*% M %*% RIGHT ) - ( LEFT %*% X %*% XtXinv) %*% ( t(X) %*% M %*% RIGHT ) " )

object.size(M_regressed)
object.size(M_regressed_lazy)
x = rnorm( ncol( M ) )
microbenchmark::microbenchmark({M_regressed      %*% x})
microbenchmark::microbenchmark({M_regressed_lazy %*% x})
```

